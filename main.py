from ultralytics import YOLO
from paddleocr import PaddleOCR
from track.sort import SORT
from track.bytetrack import ByteTrack
from detect.detect import inference_video
from core.vehicle import Vehicle
from utils.parse_args import parse_args_tracking
from utils.drawing import draw_polygon_zone, render_frame
from utils.io import handle_result_filename, violation_save_worker
from detect.utils import preprocess_detection_result
from core.violation import RedLightViolation
from core.violation_manager import ViolationManager
from core.license_plate_recognizer import LicensePlateRecognizer
from utils.config import load_config
import cv2
import numpy as np
import supervision as sv
import os
import csv
import threading
import queue
from collections import deque
import line_profiler

@line_profiler.profile
def main():
    os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp"
    args = parse_args_tracking()

    # Prepare output paths
    result_filename, ext = handle_result_filename(args.data_path, args.tracker)
    video_result_path = os.path.join(args.output_dir, "video", result_filename + ext)
    csv_result_path = os.path.join(args.output_dir, "csv", result_filename + ".csv")
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "video"), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "csv"), exist_ok=True)

    # Load config
    config = load_config()

    # Point to MediMTX RTSP if using "cam_ai" mode
    if args.data_path == "cam_ai":
        # Local RTSP link generated by MediaMTX SRT
        args.data_path = "rtsp://localhost:8554/cam_ai"
        print(f"-> Đang kết nối chế độ SRT/H.265 qua MediaMTX: {args.data_path}")
    
    if args.tracker == 'sort':
        cfg = config['tracking']['sort']
        tracker_instance = SORT(
            cost_function=cfg['cost_function'], 
            max_age=cfg['max_age'], 
            min_hits=cfg['min_hits'], 
            iou_threshold=cfg['iou_threshold'], 
            tracker_class=Vehicle
        )
        conf_threshold = cfg['conf_threshold']
    elif args.tracker == 'bytetrack':
        cfg = config['tracking']['bytetrack']
        tracker_instance = ByteTrack(
            cost_function=cfg['cost_function'], 
            max_age=cfg['max_age'], 
            min_hits=cfg['min_hits'], 
            high_conf_threshold=cfg['high_conf_threshold'], 
            low_conf_threshold=cfg['low_conf_threshold'],
            high_conf_iou_threshold=cfg['high_conf_iou_threshold'],
            low_conf_iou_threshold=cfg['low_conf_iou_threshold'],
            tracker_class=Vehicle
        )
        conf_threshold = cfg['conf_threshold']
    else:
        raise ValueError(f"Unknown tracker: {args.tracker}")

    data_path = args.data_path
    vehicle_model = YOLO(args.vehicle_model, task='detect', verbose=True)
    license_model = YOLO(args.license_model, task='detect', verbose=True)
    # character_model = YOLO(args.character_model, task='detect', verbose=True)
    character_model = PaddleOCR(use_angle_cls=True, lang='en')
    
    device = args.device
    violation_queue = queue.Queue()
    worker_thread = threading.Thread(target=violation_save_worker,args=(violation_queue,), daemon=True)
    worker_thread.start()
    np.random.seed(42)
    window_name = "Traffic Violation Detection"

    # supervision annotator for visualization
    box_annotator = sv.BoxAnnotator(thickness=2)
    label_annotator = sv.LabelAnnotator(text_scale=0.5, text_padding=5)

    cv2.namedWindow(window_name, cv2.WND_PROP_FULLSCREEN)

    # Prepare detections
    dets = inference_video(
        model=vehicle_model,
        data_path=data_path,
        output_path=None,
        device=device,
        stream=True,
        conf_threshold=conf_threshold,
        classes=config['detections']['classes'],
        imgsz=config['detections']['imgsz'],
        iou_threshold=config['detections']['iou_threshold'],
        stream_buffer=False
    )
    csv_results = []

    # First run
    first_run = True

    for i, result in enumerate(dets):
        if first_run:
            # Setup Window display
            first_frame = result.orig_img
            FRAME_WIDTH, FRAME_HEIGHT = first_frame.shape[1], first_frame.shape[0]
            FPS = config['violation']['fps'] if config['violation']['fps'] is not None else 30
            polygon_points = draw_polygon_zone(first_frame, window_name)
            polygon_points = np.array(polygon_points, dtype=int)
            polygon_zone = sv.PolygonZone(polygon_points, triggering_anchors=[sv.Position.CENTER]) if len(polygon_points) >= 3 else None

            # Frame buffer for video proof
            buffer_duration = config['violation']['video_proof_duration']
            buffer_maxlen = int(FPS * buffer_duration)
            frame_buffer = deque(maxlen=buffer_maxlen)

            # Set up violation manager and violation types
            violations = [RedLightViolation(polygon_points=polygon_points, frame=first_frame, window_name=window_name)]
            licensePlate_recognizer = LicensePlateRecognizer(license_model=license_model, character_model=character_model)
            violation_manager = ViolationManager(violations=violations, recognizer=licensePlate_recognizer)
            first_run = False

        frame, det = preprocess_detection_result(result)

        # Object tracking
        tracked_objs = tracker_instance.update(dets=det)

        # Can optimize for better performance, now using 2 for loops for simplicity
        states = [obj.get_state()[0] for obj in tracked_objs]
        ids = [obj.id for obj in tracked_objs] 
        cls_ids = [obj.class_id for obj in tracked_objs]
        if len(states) == 0:
            sv_detections = sv.Detections.empty()
        else:
            xyxy = np.array(states)
            tracker_ids = np.array(ids)
            tracker_cls_ids = np.array(cls_ids)
            sv_detections = sv.Detections(
                xyxy=xyxy,
                tracker_id=tracker_ids,
                class_id=tracker_cls_ids
            )

        in_zone_mask = polygon_zone.trigger(detections=sv_detections)
        for obj in tracked_objs:
            if obj.is_being_tracked == False and obj.id in sv_detections.tracker_id[in_zone_mask]:
                obj.is_being_tracked = True

        visualized_tracked_objs = [obj for obj in tracked_objs if obj.is_being_tracked]
        visualize_mask = np.isin(sv_detections.tracker_id, [obj.id for obj in visualized_tracked_objs])
        visualized_sv_detections = sv_detections[visualize_mask]

        # Update frame buffer
        frame_buffer.append(frame.copy())

        # Update violation manager
        violation_manager.update(vehicles=visualized_tracked_objs, sv_detections=visualized_sv_detections, frame=frame, traffic_light_state=[None, 'RED', 'RED'], frame_buffer=frame_buffer, fps=FPS, save_queue=violation_queue)
        
        render_frame(visualized_tracked_objs, frame, visualized_sv_detections, box_annotator, label_annotator)

        if args.save == "True":
            frame_num = i + 1
            for obj in visualized_tracked_objs:
                x1, y1, x2, y2 = map(float, obj.get_state()[0])
                t_id = int(obj.id)
                violated = 1 if getattr(obj, 'has_violated', False) else 0

                csv_results.append([frame_num, x1, y1, x2, y2, t_id, violated])
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cv2.destroyAllWindows()

    # Save results to CSV
    if args.save == "True":
        with open(csv_result_path, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerows(csv_results)
    print(f"Tracking results succesfully saved to {video_result_path} and {csv_result_path}")
    print(FRAME_WIDTH, FRAME_HEIGHT, FPS)
    print(len(csv_results))

if __name__ == "__main__":
    main()