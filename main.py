from ultralytics import YOLO
from paddleocr import PaddleOCR
from track.sort import SORT
from track.bytetrack import ByteTrack
from detect.detect import inference_video
from core.vehicle import Vehicle
from utils.parse_args import parse_args_tracking
from utils.drawing import draw_polygon_zone, render_frame
from utils.io import handle_result_filename, violation_save_worker
from detect.utils import preprocess_detection_result
from core.violation import RedLightViolation
from core.violation_manager import ViolationManager
from core.license_plate_recognizer import LicensePlateRecognizer
from core.light_signal_detector import LightSignalDetector
from core.light_signal_FSM import LightSignalFSM
from utils.config import load_config
import cv2
import numpy as np
import supervision as sv
import os
import csv
import threading
import queue
import time
from collections import deque
import line_profiler

@line_profiler.profile
def main():
    os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp"
    os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
    args = parse_args_tracking()

    # Prepare output paths
    result_filename, ext = handle_result_filename(args.data_path, args.tracker)
    video_result_path = os.path.join(args.output_dir, "video", result_filename + ext)
    csv_result_path = os.path.join(args.output_dir, "csv", result_filename + ".csv")
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "video"), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "csv"), exist_ok=True)

    # Load config
    config = load_config()

    # Point to MediMTX RTSP if using "cam_ai" mode
    if args.data_path == "cam_ai":
        # Local RTSP link generated by MediaMTX SRT
        args.data_path = "rtsp://localhost:8554/cam_ai"
        print(f"-> Đang kết nối chế độ SRT/H.265 qua MediaMTX: {args.data_path}")
    
    if args.tracker == 'sort':
        cfg = config['tracking']['sort']
        tracker_instance = SORT(
            cost_function=cfg['cost_function'], 
            max_age=cfg['max_age'], 
            min_hits=cfg['min_hits'], 
            iou_threshold=cfg['iou_threshold'], 
            tracker_class=Vehicle
        )
        conf_threshold = cfg['conf_threshold']
    elif args.tracker == 'bytetrack':
        cfg = config['tracking']['bytetrack']
        tracker_instance = ByteTrack(
            cost_function=cfg['cost_function'], 
            max_age=cfg['max_age'], 
            min_hits=cfg['min_hits'], 
            high_conf_threshold=cfg['high_conf_threshold'], 
            low_conf_threshold=cfg['low_conf_threshold'],
            high_conf_iou_threshold=cfg['high_conf_iou_threshold'],
            low_conf_iou_threshold=cfg['low_conf_iou_threshold'],
            tracker_class=Vehicle
        )
        conf_threshold = cfg['conf_threshold']
    else:
        raise ValueError(f"Unknown tracker: {args.tracker}")

    data_path = args.data_path
    vehicle_model = YOLO(args.vehicle_model, task='detect', verbose=False)
    license_model = YOLO(args.license_model, task='detect', verbose=False)
    # character_model = YOLO(args.character_model, task='detect', verbose=True)
    character_model = PaddleOCR(use_angle_cls=True, lang='en')
    
    device = args.device
    violation_queue = queue.Queue()
    worker_thread = threading.Thread(target=violation_save_worker,args=(violation_queue,), daemon=True)
    worker_thread.start()
    np.random.seed(42)
    window_name = "Traffic Violation Detection"

    # supervision annotator for visualization
    box_annotator = sv.BoxAnnotator(thickness=2)
    label_annotator = sv.LabelAnnotator(text_scale=0.5, text_padding=5)

    cv2.namedWindow(window_name, cv2.WND_PROP_FULLSCREEN)

    # Prepare detections
    dets = inference_video(
        model=vehicle_model,
        data_path=data_path,
        output_path=None,
        device=device,
        stream=True,
        conf_threshold=conf_threshold,
        classes=config['detections']['classes'],
        imgsz=config['detections']['imgsz'],
        iou_threshold=config['detections']['iou_threshold'],
        stream_buffer=False,
        verbose=False
    )
    csv_results = []

    # First run
    first_run = True

    for i, result in enumerate(dets):
        if first_run:
            # Setup Window display
            first_frame = result.orig_img
            FRAME_WIDTH, FRAME_HEIGHT = first_frame.shape[1], first_frame.shape[0]
            FPS = config['violation']['fps'] if config['violation']['fps'] is not None else 30
            polygon_points = draw_polygon_zone(first_frame, window_name)
            polygon_points = np.array(polygon_points, dtype=int)
            polygon_zone = sv.PolygonZone(polygon_points, triggering_anchors=[sv.Position.CENTER]) if len(polygon_points) >= 3 else None

            # Frame buffer for video proof
            buffer_duration = config['violation']['video_proof_duration']
            buffer_maxlen = int(FPS * buffer_duration)
            frame_buffer = deque(maxlen=buffer_maxlen)
            frame_counter = 0

            # Set up violation manager and violation types
            violations = [RedLightViolation(polygon_points=polygon_points, frame=first_frame, window_name=window_name)]
            licensePlate_recognizer = LicensePlateRecognizer(license_model=license_model, character_model=character_model)
            violation_manager = ViolationManager(violations=violations, recognizer=licensePlate_recognizer)

            # set up light signal FSMs
            if args.light_detect == 'True':
                light_detector = LightSignalDetector(h=FRAME_HEIGHT, w=FRAME_WIDTH, frame=first_frame, window_name=window_name)
                initial_light_list = light_detector.detect_light_signals(first_frame)
                processed_initial_lights = []
                for light in initial_light_list:
                    if light is None:
                        processed_initial_lights.append(light)
                    else:
                        processed_initial_lights.append(light[0])  # Extract only the state

                light_fsm = LightSignalFSM(initial_states=processed_initial_lights)

            first_run = False

        frame, det = preprocess_detection_result(result)
        frame_counter += 1

        # Object tracking
        tracked_objs = tracker_instance.update(dets=det)
        all_tracked_objs = tracker_instance.get_tracked_objects()

        # Prepare detections in supervision format
        states = [obj.get_state()[0] for obj in tracked_objs]
        ids = [obj.id for obj in tracked_objs] 
        cls_ids = [obj.class_id for obj in tracked_objs]
        if len(states) == 0:
            sv_detections = sv.Detections.empty()
        else:
            xyxy = np.array(states)
            tracker_ids = np.array(ids)
            tracker_cls_ids = np.array(cls_ids)
            sv_detections = sv.Detections(
                xyxy=xyxy,
                tracker_id=tracker_ids,
                class_id=tracker_cls_ids
            )

        # Filter vehicles inside polygon zone
        in_zone_mask = polygon_zone.trigger(detections=sv_detections)

        for obj in all_tracked_objs:
            if obj.is_being_tracked == False and sv_detections.tracker_id is not None and obj.id in sv_detections.tracker_id[in_zone_mask]:
                obj.is_being_tracked = True
            if obj.bboxes_buffer is not None:
                obj.bboxes_buffer.append((frame_counter, obj.get_state()[0]))
            else:
                obj.bboxes_buffer = deque(maxlen=buffer_maxlen)
                obj.bboxes_buffer.append((frame_counter, obj.get_state()[0]))

        visualized_tracked_objs = [obj for obj in tracked_objs if obj.is_being_tracked]
        visualize_mask = np.isin(sv_detections.tracker_id, [obj.id for obj in visualized_tracked_objs])
        visualized_sv_detections = sv_detections[visualize_mask]

        # Update frame buffer
        frame_buffer.append((frame_counter, frame.copy()))

        # Update light signal FSMs
        if args.light_detect == 'True':
            # to improve FPS, as heavy masking is quite costly (masking every frame drops the FPS to about 13)
            if frame_counter % 5 == 0:
                detected_lights = light_detector.detect_light_signals(frame)
                traffic_light_states = light_fsm.update(candidates=detected_lights, frame_idx=frame_counter)
            else:
                traffic_light_states = light_fsm.get_states()
        else:
            # This means the tracking is part of a larger system where traffic light states are provided externally
            # For now, we set them to None RED None
            traffic_light_states = [None, 'RED', None]

        # Update violation manager
        violation_manager.update(vehicles=visualized_tracked_objs, sv_detections=visualized_sv_detections, frame=frame, traffic_light_state=traffic_light_states, frame_buffer=frame_buffer, fps=FPS, save_queue=violation_queue)
        
        frame = render_frame(visualized_tracked_objs, frame, visualized_sv_detections, box_annotator, label_annotator)
        cv2.imshow(window_name, frame)

        if args.save == "True":
            frame_num = i + 1
            for obj in visualized_tracked_objs:
                x1, y1, x2, y2 = map(float, obj.get_state()[0])
                t_id = int(obj.id)
                violated = 1 if getattr(obj, 'has_violated', False) else 0

                csv_results.append([frame_num, x1, y1, x2, y2, t_id, violated])
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cv2.destroyAllWindows()

    # wait for violation saving queue to be empty
    while violation_queue.qsize() > 0:
        print(
        f"\r[Main] Waiting for violation queue to be empty. Remaining items: {violation_queue.qsize():3d}",
        end="",
        flush=True,
    )
        time.sleep(0.1)

    time.sleep(1)  # Ensure all items are processed
    violation_queue.put(None)  # Stop the worker thread
    worker_thread.join()

    # Save results to CSV
    if args.save == "True":
        with open(csv_result_path, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerows(csv_results)
        print(f"Tracking results succesfully saved to {video_result_path} and {csv_result_path}")
    print(FRAME_WIDTH, FRAME_HEIGHT, FPS)
    print(len(csv_results))

if __name__ == "__main__":
    main()